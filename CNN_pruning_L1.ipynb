{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L47XBZWm4T9x",
        "outputId": "4845f095-7910-4380-99d3-ee5e49fb1161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.10.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1FQTVeAuNiU",
        "outputId": "2c956ab4-95e2-4992-effa-e5659c69bfb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x train_images.pkl\n",
            "x train_labels.pkl\n",
            "x val_images.pkl\n",
            "x val_labels.pkl\n"
          ]
        }
      ],
      "source": [
        "# untar\n",
        "!tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTzcSoYl4T97",
        "outputId": "5949a8dd-b44a-47a7-fd0c-4b8ecb0fdc41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 11, 11, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Nk_MAPqZPt",
        "outputId": "30f25f9c-0ac0-418e-aab1-bfde789e6ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-30 14:43:20.461072: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "/Users/kelaba/mambaforge/envs/bioimage/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "703/703 [==============================] - 16s 22ms/step - loss: 1.5304 - accuracy: 0.2989 - val_loss: 1.3970 - val_accuracy: 0.4083\n",
            "Epoch 2/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 1.3507 - accuracy: 0.4238 - val_loss: 1.2846 - val_accuracy: 0.4463\n",
            "Epoch 3/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 1.2866 - accuracy: 0.4541 - val_loss: 1.2351 - val_accuracy: 0.4756\n",
            "Epoch 4/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 1.2427 - accuracy: 0.4826 - val_loss: 1.1827 - val_accuracy: 0.5046\n",
            "Epoch 5/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 1.2064 - accuracy: 0.5030 - val_loss: 1.1340 - val_accuracy: 0.5295\n",
            "Epoch 6/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 1.1719 - accuracy: 0.5225 - val_loss: 1.1061 - val_accuracy: 0.5556\n",
            "Epoch 7/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 1.1422 - accuracy: 0.5386 - val_loss: 1.1909 - val_accuracy: 0.5145\n",
            "Epoch 8/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.1153 - accuracy: 0.5535 - val_loss: 1.0585 - val_accuracy: 0.5644\n",
            "Epoch 9/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 1.0892 - accuracy: 0.5657 - val_loss: 1.0348 - val_accuracy: 0.5826\n",
            "Epoch 10/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 1.0660 - accuracy: 0.5761 - val_loss: 1.0021 - val_accuracy: 0.5881\n",
            "Epoch 11/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 1.0497 - accuracy: 0.5840 - val_loss: 1.0199 - val_accuracy: 0.5865\n",
            "Epoch 12/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 1.0269 - accuracy: 0.5933 - val_loss: 0.9682 - val_accuracy: 0.6174\n",
            "Epoch 13/50\n",
            "703/703 [==============================] - 12s 17ms/step - loss: 1.0099 - accuracy: 0.6030 - val_loss: 0.9973 - val_accuracy: 0.6012\n",
            "Epoch 14/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.9911 - accuracy: 0.6092 - val_loss: 0.9369 - val_accuracy: 0.6238\n",
            "Epoch 15/50\n",
            "703/703 [==============================] - 12s 17ms/step - loss: 0.9757 - accuracy: 0.6218 - val_loss: 0.9524 - val_accuracy: 0.6099\n",
            "Epoch 16/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.9563 - accuracy: 0.6289 - val_loss: 0.9190 - val_accuracy: 0.6416\n",
            "Epoch 17/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.9447 - accuracy: 0.6317 - val_loss: 0.9162 - val_accuracy: 0.6349\n",
            "Epoch 18/50\n",
            "703/703 [==============================] - 16s 23ms/step - loss: 0.9245 - accuracy: 0.6428 - val_loss: 0.8771 - val_accuracy: 0.6495\n",
            "Epoch 19/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9142 - accuracy: 0.6448 - val_loss: 0.8858 - val_accuracy: 0.6495\n",
            "Epoch 20/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.9001 - accuracy: 0.6542 - val_loss: 0.8676 - val_accuracy: 0.6562\n",
            "Epoch 21/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.8827 - accuracy: 0.6583 - val_loss: 0.8541 - val_accuracy: 0.6634\n",
            "Epoch 22/50\n",
            "703/703 [==============================] - 15s 22ms/step - loss: 0.8743 - accuracy: 0.6630 - val_loss: 0.8741 - val_accuracy: 0.6634\n",
            "Epoch 23/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 0.8597 - accuracy: 0.6684 - val_loss: 0.8468 - val_accuracy: 0.6693\n",
            "Epoch 24/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8511 - accuracy: 0.6751 - val_loss: 0.8394 - val_accuracy: 0.6733\n",
            "Epoch 25/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 0.8384 - accuracy: 0.6792 - val_loss: 0.8428 - val_accuracy: 0.6709\n",
            "Epoch 26/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.8262 - accuracy: 0.6853 - val_loss: 0.8376 - val_accuracy: 0.6784\n",
            "Epoch 27/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 0.8129 - accuracy: 0.6899 - val_loss: 0.8108 - val_accuracy: 0.6816\n",
            "Epoch 28/50\n",
            "703/703 [==============================] - 14s 21ms/step - loss: 0.8088 - accuracy: 0.6937 - val_loss: 0.8236 - val_accuracy: 0.6721\n",
            "Epoch 29/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8010 - accuracy: 0.6966 - val_loss: 0.8053 - val_accuracy: 0.6855\n",
            "Epoch 30/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.7821 - accuracy: 0.7008 - val_loss: 0.8299 - val_accuracy: 0.6808\n",
            "Epoch 31/50\n",
            "703/703 [==============================] - 12s 17ms/step - loss: 0.7821 - accuracy: 0.7010 - val_loss: 0.7989 - val_accuracy: 0.6859\n",
            "Epoch 32/50\n",
            "703/703 [==============================] - 12s 17ms/step - loss: 0.7681 - accuracy: 0.7075 - val_loss: 0.7999 - val_accuracy: 0.6883\n",
            "Epoch 33/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.7585 - accuracy: 0.7111 - val_loss: 0.7781 - val_accuracy: 0.6998\n",
            "Epoch 34/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.7499 - accuracy: 0.7165 - val_loss: 0.8045 - val_accuracy: 0.6915\n",
            "Epoch 35/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.7380 - accuracy: 0.7193 - val_loss: 0.7795 - val_accuracy: 0.6958\n",
            "Epoch 36/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.7300 - accuracy: 0.7255 - val_loss: 0.7776 - val_accuracy: 0.6962\n",
            "Epoch 37/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.7188 - accuracy: 0.7269 - val_loss: 0.7778 - val_accuracy: 0.7006\n",
            "Epoch 38/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 0.7158 - accuracy: 0.7292 - val_loss: 0.7633 - val_accuracy: 0.7105\n",
            "Epoch 39/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.7063 - accuracy: 0.7370 - val_loss: 0.7556 - val_accuracy: 0.7117\n",
            "Epoch 40/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.6973 - accuracy: 0.7375 - val_loss: 0.7554 - val_accuracy: 0.7105\n",
            "Epoch 41/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.6915 - accuracy: 0.7393 - val_loss: 0.7932 - val_accuracy: 0.6978\n",
            "Epoch 42/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.6846 - accuracy: 0.7406 - val_loss: 0.7472 - val_accuracy: 0.7117\n",
            "Epoch 43/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.6684 - accuracy: 0.7470 - val_loss: 0.7625 - val_accuracy: 0.7069\n",
            "Epoch 44/50\n",
            "703/703 [==============================] - 17s 24ms/step - loss: 0.6653 - accuracy: 0.7511 - val_loss: 0.7681 - val_accuracy: 0.7057\n",
            "Epoch 45/50\n",
            "703/703 [==============================] - 15s 22ms/step - loss: 0.6627 - accuracy: 0.7518 - val_loss: 0.7528 - val_accuracy: 0.7093\n",
            "Epoch 46/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.6534 - accuracy: 0.7541 - val_loss: 0.7437 - val_accuracy: 0.7152\n",
            "Epoch 47/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.6483 - accuracy: 0.7580 - val_loss: 0.7392 - val_accuracy: 0.7200\n",
            "Epoch 48/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.6324 - accuracy: 0.7631 - val_loss: 0.7379 - val_accuracy: 0.7180\n",
            "Epoch 49/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.6280 - accuracy: 0.7602 - val_loss: 0.7364 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.6213 - accuracy: 0.7661 - val_loss: 0.7620 - val_accuracy: 0.7097\n"
          ]
        }
      ],
      "source": [
        "# you can use the default hyper-parameters for training, \n",
        "# and val accuracy ~59% after 25 epochs and > 63% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=50, \n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOhpP7M24T9_",
        "outputId": "1b320520-9868-4255-9b4f-96fd7f03b110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 18ms/step - loss: 0.7620 - accuracy: 0.7097\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vjw94aij4T-C"
      },
      "outputs": [],
      "source": [
        "# perform pruning here\n",
        "'''\n",
        "f1 pruning\n",
        "stage wise pruning - set a single pruning rate for all layers in one stage\n",
        "'''\n",
        "def prune(model, prune_rate):\n",
        "    #print(\"hello from pruning\")\n",
        "    # print(model.layers)\n",
        "\n",
        "    indices = [] #store conv layer indices\n",
        "    c = len(model.layers)\n",
        "    for i in range(c):\n",
        "        name = model.layers[i].name\n",
        "        if(name.startswith(\"conv\")):\n",
        "            w1 = model.layers[i].get_weights()[0]\n",
        "            weight = w1\n",
        "            weights_dict = {}\n",
        "            num_filters = len(weight[0,0,0,:])\n",
        "            indices.append(i)\n",
        "    \n",
        "    #print(indices)\n",
        "\n",
        "    #for i in indices:\n",
        "    for i in indices: # loop thru convs\n",
        "        layer = model.layers[i]\n",
        "        w = layer.get_weights()[0] # shape h,w,c,f\n",
        "        num_filters = w.shape[-1]\n",
        "        # print(w.shape, \"num filters: \", num_filters)\n",
        "\n",
        "        weights_dict = {}\n",
        "        num_delete = (int(num_filters * prune_rate)) + 1\n",
        "        #print(\"num filters to delete: \", num_delete)\n",
        "\n",
        "        l1_list = [] #store l1s\n",
        "        for j in range(num_filters):\n",
        "            l1 = np.sum(abs(w[:,]))\n",
        "            filt = f\"{j}\"\n",
        "            weights_dict[filt] = l1\n",
        "            l1_list.append(l1)\n",
        "        \n",
        "        weights_dict_sort = sorted(weights_dict.items(), key = lambda k: k[1])\n",
        "        # print(weights_dict_sort)\n",
        "\n",
        "        delete_indices = []\n",
        "        for i in range(num_delete):\n",
        "            delete_indices.append((int)(weights_dict_sort[i][0]))\n",
        "        \n",
        "        for i in delete_indices:\n",
        "            # print(layer.weights[0][:,:,:,i].shape)\n",
        "            layer.weights[0][:,:,:,i].assign(0)\n",
        "            # layer.weights[1][:].assign(0) #assign bias to 0?\n",
        "\n",
        "# get the weights \n",
        "# weights = model.get_weights()\n",
        "\n",
        "# you can use set_weights() to set some weights to zero, e.g.,\n",
        "# some references for pruning techniques: https://arxiv.org/pdf/1810.05270v2.pdf, https://arxiv.org/pdf/2001.04062.pdf\n",
        "\n",
        "# weights[7][:10]=0\n",
        "# model.set_weights(weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65376 39996\n"
          ]
        }
      ],
      "source": [
        "#copy model + prune\n",
        "model2 = keras.models.clone_model(model)\n",
        "model2.build() # replace 10 with number of variables in input layer\n",
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model2.set_weights(model.get_weights())\n",
        "\n",
        "prune(model2, 0.5)\n",
        "\n",
        "c = len(model2.layers)\n",
        "total_weights = 0\n",
        "zero_weights = 0\n",
        "for i in range(c):\n",
        "    name = model2.layers[i].name\n",
        "    if(name.startswith(\"conv\")):\n",
        "        w1 = model2.layers[i].get_weights()[0]\n",
        "        for weight in w1:\n",
        "            total_weights += weight.size\n",
        "            zero_weights += np.sum(weight == 0)\n",
        "\n",
        "print(total_weights, zero_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 1.6271 - accuracy: 0.2004\n"
          ]
        }
      ],
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model2.evaluate(val_images, val_labels, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.3695 - accuracy: 0.4231 - val_loss: 1.2193 - val_accuracy: 0.5129\n",
            "Epoch 2/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.2090 - accuracy: 0.5087 - val_loss: 1.1129 - val_accuracy: 0.5521\n",
            "Epoch 3/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.1586 - accuracy: 0.5305 - val_loss: 1.1613 - val_accuracy: 0.5192\n",
            "Epoch 4/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 1.1267 - accuracy: 0.5493 - val_loss: 1.0522 - val_accuracy: 0.5731\n",
            "Epoch 5/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 1.1087 - accuracy: 0.5566 - val_loss: 1.0637 - val_accuracy: 0.5636\n",
            "Epoch 6/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 1.0836 - accuracy: 0.5674 - val_loss: 1.0197 - val_accuracy: 0.5885\n",
            "Epoch 7/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.0637 - accuracy: 0.5752 - val_loss: 1.0162 - val_accuracy: 0.5921\n",
            "Epoch 8/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.0534 - accuracy: 0.5814 - val_loss: 0.9978 - val_accuracy: 0.6004\n",
            "Epoch 9/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.0440 - accuracy: 0.5869 - val_loss: 0.9750 - val_accuracy: 0.6067\n",
            "Epoch 10/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.0339 - accuracy: 0.5934 - val_loss: 0.9890 - val_accuracy: 0.5968\n",
            "Epoch 11/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 1.0209 - accuracy: 0.5947 - val_loss: 0.9841 - val_accuracy: 0.6051\n",
            "Epoch 12/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.0147 - accuracy: 0.5990 - val_loss: 0.9524 - val_accuracy: 0.6131\n",
            "Epoch 13/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 1.0032 - accuracy: 0.6036 - val_loss: 0.9514 - val_accuracy: 0.6178\n",
            "Epoch 14/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9971 - accuracy: 0.6065 - val_loss: 0.9498 - val_accuracy: 0.6107\n",
            "Epoch 15/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9871 - accuracy: 0.6083 - val_loss: 0.9320 - val_accuracy: 0.6293\n",
            "Epoch 16/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9806 - accuracy: 0.6131 - val_loss: 0.9224 - val_accuracy: 0.6293\n",
            "Epoch 17/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9734 - accuracy: 0.6190 - val_loss: 0.9050 - val_accuracy: 0.6337\n",
            "Epoch 18/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9649 - accuracy: 0.6199 - val_loss: 0.9152 - val_accuracy: 0.6325\n",
            "Epoch 19/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9575 - accuracy: 0.6273 - val_loss: 0.9032 - val_accuracy: 0.6313\n",
            "Epoch 20/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9520 - accuracy: 0.6273 - val_loss: 0.9277 - val_accuracy: 0.6265\n",
            "Epoch 21/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9507 - accuracy: 0.6309 - val_loss: 0.9008 - val_accuracy: 0.6368\n",
            "Epoch 22/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9408 - accuracy: 0.6327 - val_loss: 0.8895 - val_accuracy: 0.6416\n",
            "Epoch 23/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 0.9386 - accuracy: 0.6346 - val_loss: 0.9113 - val_accuracy: 0.6317\n",
            "Epoch 24/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9308 - accuracy: 0.6377 - val_loss: 0.9066 - val_accuracy: 0.6281\n",
            "Epoch 25/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.9310 - accuracy: 0.6345 - val_loss: 0.8756 - val_accuracy: 0.6479\n",
            "Epoch 26/50\n",
            "703/703 [==============================] - 14s 19ms/step - loss: 0.9216 - accuracy: 0.6403 - val_loss: 0.8664 - val_accuracy: 0.6570\n",
            "Epoch 27/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.9168 - accuracy: 0.6438 - val_loss: 0.8700 - val_accuracy: 0.6547\n",
            "Epoch 28/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9132 - accuracy: 0.6457 - val_loss: 0.8620 - val_accuracy: 0.6531\n",
            "Epoch 29/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.9086 - accuracy: 0.6477 - val_loss: 0.8641 - val_accuracy: 0.6570\n",
            "Epoch 30/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 0.8979 - accuracy: 0.6525 - val_loss: 0.8568 - val_accuracy: 0.6578\n",
            "Epoch 31/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.9006 - accuracy: 0.6510 - val_loss: 0.8595 - val_accuracy: 0.6550\n",
            "Epoch 32/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8951 - accuracy: 0.6514 - val_loss: 0.8651 - val_accuracy: 0.6499\n",
            "Epoch 33/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8887 - accuracy: 0.6582 - val_loss: 0.8488 - val_accuracy: 0.6642\n",
            "Epoch 34/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8833 - accuracy: 0.6577 - val_loss: 0.8475 - val_accuracy: 0.6701\n",
            "Epoch 35/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8811 - accuracy: 0.6608 - val_loss: 0.8332 - val_accuracy: 0.6669\n",
            "Epoch 36/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8783 - accuracy: 0.6606 - val_loss: 0.8495 - val_accuracy: 0.6642\n",
            "Epoch 37/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8811 - accuracy: 0.6580 - val_loss: 0.8320 - val_accuracy: 0.6725\n",
            "Epoch 38/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8731 - accuracy: 0.6646 - val_loss: 0.8352 - val_accuracy: 0.6685\n",
            "Epoch 39/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8646 - accuracy: 0.6675 - val_loss: 0.8259 - val_accuracy: 0.6737\n",
            "Epoch 40/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8638 - accuracy: 0.6645 - val_loss: 0.8403 - val_accuracy: 0.6673\n",
            "Epoch 41/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8574 - accuracy: 0.6715 - val_loss: 0.8407 - val_accuracy: 0.6638\n",
            "Epoch 42/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8583 - accuracy: 0.6691 - val_loss: 0.8297 - val_accuracy: 0.6725\n",
            "Epoch 43/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8595 - accuracy: 0.6692 - val_loss: 0.8209 - val_accuracy: 0.6764\n",
            "Epoch 44/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8509 - accuracy: 0.6750 - val_loss: 0.8217 - val_accuracy: 0.6780\n",
            "Epoch 45/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8448 - accuracy: 0.6773 - val_loss: 0.8194 - val_accuracy: 0.6820\n",
            "Epoch 46/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8477 - accuracy: 0.6752 - val_loss: 0.8111 - val_accuracy: 0.6788\n",
            "Epoch 47/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 0.8395 - accuracy: 0.6791 - val_loss: 0.8289 - val_accuracy: 0.6729\n",
            "Epoch 48/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8394 - accuracy: 0.6789 - val_loss: 0.8340 - val_accuracy: 0.6804\n",
            "Epoch 49/50\n",
            "703/703 [==============================] - 12s 18ms/step - loss: 0.8283 - accuracy: 0.6824 - val_loss: 0.8334 - val_accuracy: 0.6741\n",
            "Epoch 50/50\n",
            "703/703 [==============================] - 13s 18ms/step - loss: 0.8290 - accuracy: 0.6805 - val_loss: 0.8168 - val_accuracy: 0.6788\n"
          ]
        }
      ],
      "source": [
        "#train again with pruned\n",
        "\n",
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model2.fit(train_images, train_labels, batch_size=32, epochs=50, \n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 18ms/step - loss: 0.8168 - accuracy: 0.6788\n"
          ]
        }
      ],
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model2.evaluate(val_images, val_labels, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "oUuNXFjV4T-E",
        "outputId": "3044b45b-08f4-4723-89ef-415936308710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "592933 40114\n",
            "0.37322675614276823\n"
          ]
        }
      ],
      "source": [
        "#get num_zero + score\n",
        "total_weights = 0\n",
        "zero_weights = 0\n",
        "all_model2_weights = model2.get_weights()\n",
        "for weight in all_model2_weights:\n",
        "  total_weights += weight.size\n",
        "  zero_weights += np.sum(weight == 0)\n",
        "\n",
        "print(total_weights, zero_weights)\n",
        "print(( 0.6788 + zero_weights/total_weights)/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wMSKQW4k4T-G",
        "outputId": "dd51500d-60c2-4774-e477-3933e6f323fc"
      },
      "outputs": [],
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model2.save_weights(\"my_model_weights.h5\")\n",
        "\n",
        "# # running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "# from google.colab import files\n",
        "# files.download(\"my_model_weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#accuracy vs sparsity curve:\n",
        "spa = [0.6]\n",
        "acc = [0.6788]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#copy model + prune\n",
        "model2 = keras.models.clone_model(model)\n",
        "model2.set_weights(model.get_weights())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kelaba/mambaforge/envs/bioimage/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "703/703 [==============================] - 14s 19ms/step - loss: 1.1644 - accuracy: 0.5295 - val_loss: 0.9934 - val_accuracy: 0.6135\n",
            "Epoch 2/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 1.0123 - accuracy: 0.6020 - val_loss: 0.9635 - val_accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 0.9558 - accuracy: 0.6275 - val_loss: 0.8990 - val_accuracy: 0.6400\n",
            "Epoch 4/50\n",
            "703/703 [==============================] - 15s 21ms/step - loss: 0.9158 - accuracy: 0.6464 - val_loss: 0.8614 - val_accuracy: 0.6626\n",
            "Epoch 5/50\n",
            "703/703 [==============================] - 13s 19ms/step - loss: 0.8794 - accuracy: 0.6595 - val_loss: 0.8613 - val_accuracy: 0.6653\n",
            "Epoch 6/50\n",
            "703/703 [==============================] - 17s 24ms/step - loss: 0.8556 - accuracy: 0.6693 - val_loss: 0.8274 - val_accuracy: 0.6780\n",
            "Epoch 7/50\n",
            "703/703 [==============================] - 18s 25ms/step - loss: 0.8312 - accuracy: 0.6812 - val_loss: 0.8465 - val_accuracy: 0.6681\n",
            "Epoch 8/50\n",
            "703/703 [==============================] - 14s 20ms/step - loss: 0.8215 - accuracy: 0.6862 - val_loss: 0.8430 - val_accuracy: 0.6776\n",
            "Epoch 9/50\n",
            "703/703 [==============================] - 14s 19ms/step - loss: 0.8043 - accuracy: 0.6945 - val_loss: 0.7988 - val_accuracy: 0.6836\n",
            "Epoch 10/50\n",
            "703/703 [==============================] - 17s 24ms/step - loss: 0.7886 - accuracy: 0.6992 - val_loss: 0.8014 - val_accuracy: 0.6840\n",
            "Epoch 11/50\n",
            "391/703 [===============>..............] - ETA: 5s - loss: 0.7859 - accuracy: 0.6987"
          ]
        }
      ],
      "source": [
        "prune(model2, 0.5)\n",
        "\n",
        "#train again with pruned\n",
        "\n",
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model2.fit(train_images, train_labels, batch_size=32, epochs=50, \n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39;49mevaluate(val_images, val_labels, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m)\n",
            "File \u001b[0;32m~/mambaforge/envs/bioimage/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/mambaforge/envs/bioimage/lib/python3.9/site-packages/keras/engine/training.py:3618\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_compile_was_called\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   3613\u001b[0m     \u001b[39m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3614\u001b[0m     \u001b[39m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3615\u001b[0m     \u001b[39m# model is compiled\u001b[39;00m\n\u001b[1;32m   3616\u001b[0m     \u001b[39m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3617\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3618\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   3619\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must compile your model before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3620\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtraining/testing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3621\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3622\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ],
      "source": [
        "results = model2.evaluate(val_images, val_labels, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('bioimage')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea60e39e41cb5f972aeea0d91b3f1356a90c0c1cec13235e9cf42bf76c36d728"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
